# -*- coding: utf-8 -*-
"""ChessPieceRecognition_Raw.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1r-NorGhwnZUgDesZPZ7GULF5Mc6zdWdS
"""

!pip install -q kaggle

# Upload the kaggle.json file
print("Please upload the kaggle.json file")
from google.colab import files
files.upload()

!rm -r ~/.kaggle
!mkdir ~/.kaggle
!mv ./kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
# !kaggle datasets list

# Download the Chess Piece Dataset
!kaggle datasets download anshulmehtakaggl/chess-pieces-detection-images-dataset/code -p /content/sample_data/ --unzip

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import PIL
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import Sequential, layers
from tensorflow.keras.callbacks import EarlyStopping

datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    zoom_range=(0.8, 1.2),
    rescale=1/255,
    validation_split=0.2)

train_augmented = datagen.flow_from_directory(
    "/content/sample_data/",
    target_size=(224,224),
    subset="training"
)

val_augmented = datagen.flow_from_directory(
    "/content/sample_data/",
    target_size=(224,224),
    subset="validation")

def initialize_model():
    model = Sequential()
    model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(224, 224, 3)))
    model.add(layers.Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
    model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
    model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Flatten())
    model.add(layers.Dense(128, activation='relu', kernel_initializer='he_uniform'))
    model.add(layers.Dense(5, activation='softmax'))

    return model

def compile_model(model):
    model.compile(loss="categorical_crossentropy",
                 optimizer="adam",
                 metrics="accuracy")
    return model

model = compile_model(initialize_model())

model.summary()

es = EarlyStopping(patience=15)

history = model.fit(train_augmented,
                    epochs=50,
                    batch_size=16,
                   # steps_per_epoch=train_augmented.samples//train_augmented.batch_size,
                    callbacks=es,
                    verbose=1,
                    validation_data=val_augmented)

def plot_history(history, title='', axs=None, exp_name=""):
    if axs is not None:
        ax1, ax2 = axs
    else:
        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    if len(exp_name) > 0 and exp_name[0] != '_':
        exp_name = '_' + exp_name
    ax1.plot(history.history['loss'], label='Training' + exp_name)
    ax1.plot(history.history['val_loss'], label='Validation' + exp_name)
    ax1.set_ylim(0.0, 2.2)
    ax1.set_title('Loss')
    ax1.legend()
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy % / 100")
    
    ax2.plot(history.history['accuracy'], label='Training Accuracy'  + exp_name)
    ax2.plot(history.history['val_accuracy'], label='Validation Accuracy'  + exp_name)
    ax2.set_ylim(0.0, 1.0)
    ax2.set_title('Raw Data Training Accuracy')
    ax2.legend()
    return (ax1, ax2)

plot_history(history)
print(f"Minimum: {round(100 * min(history.history['loss']), 4)}")
print(f"Maximum: {round(100 * max(history.history['accuracy']), 4)}")