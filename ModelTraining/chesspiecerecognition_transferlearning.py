# -*- coding: utf-8 -*-
"""ChessPieceRecognition_TransferLearning.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tTXFd6BL53wWLiBRwSGjT2JfD5JwGSnk
"""

!pip install -q kaggle

# Upload the kaggle.json file
print("Please upload the kaggle.json that contains your API Key")
from google.colab import files
files.upload()

!rm -r ~/.kaggle
!mkdir ~/.kaggle
!mv ./kaggle.json ~/.kaggle/
!chmod 600 ~/.kaggle/kaggle.json
# !kaggle datasets list

# Download the Chess Piece Dataset
!kaggle datasets download anshulmehtakaggl/chess-pieces-detection-images-dataset/code -p /content/sample_data/ --unzip

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import PIL
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras import Sequential, layers
from tensorflow.keras.callbacks import EarlyStopping

datagen = ImageDataGenerator(
    rotation_range=10,
    width_shift_range=0.1,
    height_shift_range=0.1,
    horizontal_flip=True,
    zoom_range=(0.8, 1.2),
    rescale=1/255,
    validation_split=0.2)

train_augmented = datagen.flow_from_directory(
    "/content/sample_data/",
    target_size=(224,224),
    subset="training"
)

val_augmented = datagen.flow_from_directory(
    "/content/sample_data/",
    target_size=(224,224),
    subset="validation")

import tensorflow as tf

mobilenet_model = tf.keras.applications.MobileNetV2(input_shape=(224,224,3),
                                                   include_top=False,
                                                   weights="imagenet")

mobilenet_model.trainable = False

mobilenet_model.summary()

mn_model = Sequential()
mn_model.add(mobilenet_model)
mn_model.add(layers.Flatten())
mn_model.add(layers.Dense(5,activation="softmax"))

mn_model.compile(optimizer = 'Adam', loss = 'categorical_crossentropy', metrics=['accuracy'])

earlyStopping = EarlyStopping(patience=15)

history = mn_model.fit(train_augmented,
                    epochs=50,
                    batch_size=16,
                   # steps_per_epoch=train_augmented.samples//train_augmented.batch_size,
                    callbacks=earlyStopping,
                    verbose=1,
                    validation_data=val_augmented)

print(f"Minimum: {round(100 * min(history.history['loss']), 4)}")
print(f"Maximim: {round(100 * max(history.history['accuracy']), 4)}")

def plot_history(history, title='', axs=None, exp_name=""):
    if axs is not None:
        ax1, ax2 = axs
    else:
        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))
    
    if len(exp_name) > 0 and exp_name[0] != '_':
        exp_name = '_' + exp_name
    ax1.plot(history.history['loss'], label='train' + exp_name)
    ax1.plot(history.history['val_loss'], label='val' + exp_name)
    ax1.set_ylim(0., 2.2)
    ax1.set_title('loss')
    ax1.legend()
    plt.xlabel("Epochs")
    plt.ylabel("Accuracy % / 100")

    ax2.plot(history.history['accuracy'], label='Training'  + exp_name)
    ax2.plot(history.history['val_accuracy'], label='Validation'  + exp_name)
    ax2.set_ylim(0., 1.)
    ax2.set_title('Transfer Learning Training Accuracy')
    ax2.legend()
    return (ax1, ax2)

plot_history(history)

from google.colab import drive
drive.mount('/content/gdrive/')

mn_model.save("/content/gdrive/MyDrive/CS4460-5460-Chess_models/")